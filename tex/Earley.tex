\chapter{Earley Parsing}
\label{cha:Earley}

The CKY parser is a non-directional bottom-up parser with a chart, but chart parsing is in no way restricted to these parameters.
In this chapter, we look at a directional chart parser with a top-down component: the Earley parser.
The Earley parser combines a variety of techniques and insights we have encountered up to this point, and we will emphasize these connections by carefully working out the relation between Earley parsing and LC parsing.
The Earley parser is also one of the fastest known algorithms for arbitrary CFGs, and in contrast to the CKY parser it does not require grammars to be in Chomsky Normal Form.
In addition, Earley parsing has shown promise in some psycholinguistic modeling experiments \citep{Hale01}, which will be discussed further in Cha.~\ref{cha:Prob}.


\section{Intuition}

There are two intuitive perspectives of Earley parsing.
We may either view it as a top-down parser where predictions are restricted by bottom-up reductions, or as a bottom-up parser where reductions are restricted by top-down predictions.
In either case we are clearly dealing with a model that mixes top-down and bottom-up aspects, similar to the LC parser.

The basic idea is that the parser may freely make predictions like a top-down parser, while also using bottom-up information to quickly discard incompatible predictions before they have been fully explored.
The parser moves through the input from left-to-right while trying to construct an arc that spans from the first position to the last.
Arcs are just convenient abstractions of subtrees in this context.
If the end position of one arcs is the start position of another arc, they can be combined into a larger arc, just like two subtrees can be combined into a single tree by attaching them below a new node.
The strength of the Earley parser is how it avoids spending time on arcs that are bound to fail.

All of this is best explained through a concrete example.
Suppose that we have our usual toy grammar and want to parse the input sentence \emph{The anvil hit Daffy}, represented here as an indexed string.
%
\begin{center}
    \begin{tikzpicture}
        \node[state]           (0) at (0,0) {0};
        \node[state]           (1) [right=of 0] {1};
        \node[state]           (2) [right=of 1] {2};
        \node[state]           (3) [right=of 2] {3};
        \node[state]           (4) [right=of 3] {4};

        \path[->] (0) edge node [above] {the} (1)
                  (1) edge node [above] {anvil} (2)
                  (2) edge node [above] {hit} (3)
                  (3) edge node [above] {Daffy} (4);
    \end{tikzpicture}
\end{center}
%
The parser will start out by conjecturing an arc from $0$ to $0$ that is labeled S \rewrite\ \psep NP VP.
This is tantamount to the prediction that there will be an S-arc starting in position $0$, but so far we have not recognized an NP or a VP, so the confirmed part of the arc ends in position $0$.
%
\begin{center}
    \begin{tikzpicture}
        \node[state]           (0) at (0,0) {0};
        \node[state]           (1) [right=of 0] {1};
        \node[state]           (2) [right=of 1] {2};
        \node[state]           (3) [right=of 2] {3};
        \node[state]           (4) [right=of 3] {4};

        \path[->] (0) edge node [above] {the} (1)
                  (1) edge node [above] {anvil} (2)
                  (2) edge node [above] {hit} (3)
                  (3) edge node [above] {Daffy} (4);

        \clip (-8em,0) rectangle (10em,13em);

        \path (0) edge [loop,min distance=20em,out=160,in=60] node [above] {S $\rewrite \psep$ NP VP} (0);
    \end{tikzpicture}
\end{center}
%
Since the S-arc can only be expanded in the presence of an NP, we also add arcs for the relevant NP-predictions.
%
\begin{center}
    \begin{tikzpicture}
        \node[state]           (0) at (0,0) {0};
        \node[state]           (1) [right=of 0] {1};
        \node[state]           (2) [right=of 1] {2};
        \node[state]           (3) [right=of 2] {3};
        \node[state]           (4) [right=of 3] {4};

        \path[->] (0) edge node [above] {the} (1)
                  (1) edge node [above] {anvil} (2)
                  (2) edge node [above] {hit} (3)
                  (3) edge node [above] {Daffy} (4);

        \clip (-8em,0) rectangle (10em,13em);

        \path (0) edge [loop,min distance=20em,out=160,in=60] node [above] {S $\rewrite \psep$ NP VP} (0)
              (0) edge [loop,min distance=15em,out=160,in=60] node [above] {NP $\rewrite \psep$ Det N} (0)
              (0) edge [loop,min distance=10em,out=160,in=60] node [above] {NP $\rewrite \psep$ PN} (0);
    \end{tikzpicture}
\end{center}
%
Following the same line of reasoning, we also have to add branches for each possible rewriting of Det and PN\@.
We only add one Det-arc here to avoid cluttering the figure.
%
\begin{center}
    \begin{tikzpicture}
        \node[state]           (0) at (0,0) {0};
        \node[state]           (1) [right=of 0] {1};
        \node[state]           (2) [right=of 1] {2};
        \node[state]           (3) [right=of 2] {3};
        \node[state]           (4) [right=of 3] {4};

        \path[->] (0) edge node [above] {the} (1)
                  (1) edge node [above] {anvil} (2)
                  (2) edge node [above] {hit} (3)
                  (3) edge node [above] {Daffy} (4);

        \clip (-8em,0) rectangle (10em,13em);

        \path (0) edge [loop,min distance=20em,out=160,in=60] node [above] {S $\rewrite \psep$ NP VP} (0)
              (0) edge [loop,min distance=15em,out=160,in=60] node [above] {NP $\rewrite \psep$ Det N} (0)
              (0) edge [loop,min distance=10em,out=160,in=60] node [above] {NP $\rewrite \psep$ PN} (0)
              (0) edge [loop,min distance=5em,out=160,in=60] node [above] {Det $\rewrite \psep$ the} (0);
    \end{tikzpicture}
\end{center}
%
Now that we have an arc that can be expanded if we have the right terminal symbol, the parser reads in the word starting at position $0$, which is \emph{the}.
This means that we have confirmed previously predicted information of the Det-arc in position $0$, so that we also add a completed Det-arc from $0$ to $1$.
%
\begin{center}
    \begin{tikzpicture}
        \node[state]           (0) at (0,0) {0};
        \node[state]           (1) [right=of 0] {1};
        \node[state]           (2) [right=of 1] {2};
        \node[state]           (3) [right=of 2] {3};
        \node[state]           (4) [right=of 3] {4};

        \path[->] (0) edge node [above] {the} (1)
                  (1) edge node [above] {anvil} (2)
                  (2) edge node [above] {hit} (3)
                  (3) edge node [above] {Daffy} (4);

        \clip (-8em,0) rectangle (10em,13em);

        \path (0) edge [loop,min distance=20em,out=160,in=60] node [above] {S $\rewrite \psep$ NP VP} (0)
              (0) edge [loop,min distance=15em,out=160,in=60] node [above] {NP $\rewrite \psep$ Det N} (0)
              (0) edge [loop,min distance=10em,out=160,in=60] node [above] {NP $\rewrite \psep$ PN} (0)
              (0) edge [loop,min distance=5em,out=160,in=60] node [above] {Det $\rewrite \psep$ the} (0)
              (0) edge [loop,min distance=1em,out=50,in=90] node [above, pos=.75] {Det $\rewrite$ the \psep} (1);
    \end{tikzpicture}
\end{center}
%
We can now combine this arc with the NP \rewrite\ \psep Det N arc from $0$ to $0$ to produce a new arc NP \rewrite\ Det \psep N from $0$ to $1$.
%
\begin{center}
    \begin{tikzpicture}
        \node[state]           (0) at (0,0) {0};
        \node[state]           (1) [right=of 0] {1};
        \node[state]           (2) [right=of 1] {2};
        \node[state]           (3) [right=of 2] {3};
        \node[state]           (4) [right=of 3] {4};

        \path[->] (0) edge node [above] {the} (1)
                  (1) edge node [above] {anvil} (2)
                  (2) edge node [above] {hit} (3)
                  (3) edge node [above] {Daffy} (4);

        \clip (-8em,0) rectangle (10em,13em);

        \path (0) edge [loop,min distance=20em,out=160,in=60] node [above] {S $\rewrite \psep$ NP VP} (0)
              (0) edge [loop,min distance=15em,out=160,in=60] node [above] {NP $\rewrite \psep$ Det N} (0)
              (0) edge [loop,min distance=10em,out=160,in=60] node [above] {NP $\rewrite \psep$ PN} (0)
              (0) edge [loop,min distance=5em,out=160,in=60] node [above] {Det $\rewrite \psep$ the} (0)
              (0) edge [loop,min distance=1em,out=50,in=90] node [above, pos=.75] {Det $\rewrite$ the \psep} (1)
              (0) edge [loop,min distance=8em,out=60,in=30] node [above, pos=.4] {NP $\rewrite$ Det \psep N} (1);
    \end{tikzpicture}
\end{center}
%
This arc, in turn is used to add arcs from $1$ to $1$ that are labeled with dotted rewrite rules for N, e.g.\ N \rewrite\ \psep anvil.
We add these arcs because the NP-arc from $0$ to $1$ can only be completed if there is an N-arc starting at position $1$.
%
\begin{center}
    \begin{tikzpicture}
        \node[state]           (0) at (0,0) {0};
        \node[state]           (1) [right=of 0] {1};
        \node[state]           (2) [right=of 1] {2};
        \node[state]           (3) [right=of 2] {3};
        \node[state]           (4) [right=of 3] {4};

        \path[->] (0) edge node [above] {the} (1)
                  (1) edge node [above] {anvil} (2)
                  (2) edge node [above] {hit} (3)
                  (3) edge node [above] {Daffy} (4);

        \clip (-8em,0) rectangle (10em,13em);

        \path (0) edge [loop,min distance=20em,out=160,in=60] node [above] {S $\rewrite \psep$ NP VP} (0)
              (0) edge [loop,min distance=15em,out=160,in=60] node [above] {NP $\rewrite \psep$ Det N} (0)
              (0) edge [loop,min distance=10em,out=160,in=60] node [above] {NP $\rewrite \psep$ PN} (0)
              (0) edge [loop,min distance=5em,out=160,in=60] node [above] {Det $\rewrite \psep$ the} (0)
              (0) edge [loop,min distance=1em,out=50,in=90] node [above, pos=.75] {Det $\rewrite$ the \psep} (1)
              (0) edge [loop,min distance=8em,out=60,in=30] node [above, pos=.4] {NP $\rewrite$ Det \psep N} (1)
              (1) edge [loop below] node [below] {N $\rewrite$ \psep anvil} (1);
    \end{tikzpicture}
\end{center}

\begin{exercise}
    Continue the example parse until you have reached the S-arc.
\end{exercise}
%
\begin{exercise}
    Use this arc-drawing system to parse the sentence \emph{then anvil hit the duck on the head} with the expanded toy grammar we used for the CKY parser.
    Does this format offer a way of representing the structural ambiguity?
\end{exercise}

\section{Formal Specification}

\subsection{Parsing Schema}

In its arc-based representation the Earley parser may look rather unusual to you, but the item-based parsing schema should strike you as remarkably familiar.
Items are of the form $[i, N \rewrite \alpha \psep \beta, j]$ and indicate that an $N$-constituent starts in position $i$ and has been recognized up to position $j$.
As our axiom we pick $[0, \text{S}' \rewrite \psep \text{S},0]$.
This is just a convenient shorthand so that we do not have to posit an axiom for every rewrite rule for S in our grammar.
Given this convention, then goal item is $[0, \text{S}' \rewrite \text{S} \psep,n]$, of course.

The inference rules are variants of rules that we already encountered with the shift-reduce parser and the LC parser.
Scan turns a predicted terminal symbol into recognized information (so it is the counterpart of the LC parser's shift rule rather than the scan rule, which is used to cancel out predicted and confirmed information).
%
\begin{prooftree}
    \AxiomC{$[i, A \rewrite \alpha \psep a \beta,j]$}
    \LeftLabel{\textbf{Scan}\qquad}
    \RightLabel{$a = w_j$}
    \UnaryInfC{$[i, A \rewrite \alpha a \psep \beta, j+1]$}
\end{prooftree}
%
Predict is similar to standard top-down prediction.
But just like the CKY algorithm breaks large items into smaller ones that can be easily stored in a chart and used in several inference steps, the Earley parser predicts much smaller items that explicitly represent conjectured subtrees.
%
\begin{prooftree}
    \AxiomC{$[i, A \rewrite \alpha \psep B \beta,j]$}
    \LeftLabel{\textbf{Predict}\qquad}
    \RightLabel{$B \rewrite \gamma \in R$}
    \UnaryInfC{$[j, B \rewrite \psep \gamma, j]$}
\end{prooftree}
%
The complete rule, finally, mirrors the behavior of the LC parser's complete rule in that it turns confirmed predictions into recognized material.
The only difference is that now the combination of two parse items is needed to license this inference.
%
\begin{prooftree}
    \AxiomC{$[i, A \rewrite \alpha \psep B \beta,j]$}
    \AxiomC{$[j, B \rewrite \gamma \psep,k]$}
    \LeftLabel{\textbf{Complete}\qquad}
    \BinaryInfC{$[i, A \rewrite \alpha B \psep \beta,k]$}
\end{prooftree}

Exactly like the CKY parser, the Earley parser is mostly used as a fully parallel chart parser that explores all possible parses at the same.
The Earley parsing schema, however, is independent of such considerations and can also be applied in a purely serial fashion.
In this case the Earley parser behaves similar to a recursive-descent parser.

\begin{examplebox}[Parse Table of an Earley Parse]
    Consider once more the sentence \emph{the anvil hit Daffy}, parse with our usual toy grammar.
    Then the shortest possible sequential Earley parse yields a parse table that closely resembles the one of the recursive-descent parser.
    %
    \begin{center}
        \begin{tabular}[t]{c@{\hspace{2em}}c}
            \begin{tabular}{r|l}
                \textbf{parse item} & \textbf{inference rule}\\
                $\lbrack$0, \psep S, 4]        & axiom\\
                $\lbrack$0, \psep NP VP, 4]    & predict(1)\\
                $\lbrack$0, \psep Det N VP, 4] & predict(3)\\
                $\lbrack$0, \psep the N VP, 4] & predict(6)\\
                $\lbrack$1, \psep N VP, 4]     & scan\\
                \\
                $\lbrack$1, \psep truck VP, 4] & predict(7)\\
                $\lbrack$2, \psep VP, 4]       & scan\\
                \\
                \\
                $\lbrack$2, \psep Vt NP, 4]    & predict(5)\\
                $\lbrack$2, \psep hit NP, 4]   & predict(10)\\
                $\lbrack$3, \psep NP, 4]       & scan\\
                \\
                $\lbrack$3, \psep PN, 4]       & predict(2)\\
                $\lbrack$3, \psep Daffy, 4]    & predict(8)\\
                $\lbrack$4, \psep, 4]          & scan
                \\
                \\
                \\
                \\
                \\
            \end{tabular}
            %
            &
            %
            \begin{tabular}{r|l}
                \textbf{parse item} & \textbf{inference rule}\\
                $\lbrack$0, S$'$ \rewrite \psep S, 0]   & axiom\\
                $\lbrack$0, S \rewrite \psep NP VP, 0]  & predict(1)\\
                $\lbrack$0, NP \rewrite \psep Det N, 0] & predict(3)\\
                $\lbrack$0, Det \rewrite \psep the, 0]  & predict(6)\\
                $\lbrack$0, Det \rewrite the \psep, 1]  & scan\\
                $\lbrack$0, NP \rewrite Det \psep N, 1] & complete\\
                $\lbrack$1, N \rewrite \psep truck, 1]  & predict(7)\\
                $\lbrack$1, N \rewrite truck \psep, 2]  & scan\\
                $\lbrack$0, NP \rewrite Det N \psep, 2] & complete\\
                $\lbrack$0, S \rewrite NP \psep VP, 2]  & complete\\
                $\lbrack$2, VP \rewrite \psep Vt NP, 2] & predict(5)\\
                $\lbrack$2, Vt \rewrite \psep hit, 2]   & predict(10)\\
                $\lbrack$2, Vt \rewrite hit \psep, 3]   & scan\\
                $\lbrack$2, VP \rewrite Vt \psep NP, 3] & complete\\
                $\lbrack$3, NP \rewrite \psep PN, 3]    & predict(2)\\
                $\lbrack$3, PN \rewrite \psep Daffy, 3] & predict(8)\\
                $\lbrack$3, PN \rewrite Daffy \psep, 4] & scan\\
                $\lbrack$3, NP \rewrite PN \psep, 4]    & complete\\
                $\lbrack$2, VP \rewrite Vt NP \psep, 4] & complete\\
                $\lbrack$0, S \rewrite NP VP \psep, 4]  & complete\\
                $\lbrack$0, S$'$ \rewrite S\psep, 4]    & complete
            \end{tabular}
        \end{tabular}
    \end{center}
    %
\end{examplebox}
%
The direct comparison of parse tables in the example above highlights that we may think of the recursive-descent parser as a particular instantiation of the Earley parser: a single recursive-descent scan represents an Earley scan followed by one or more completion steps.
In general, a parser that takes fewer steps is more efficient than one that takes more steps.
So if we are interested in designing a serial parser with backtracking that does not reuse parse items, recursive-descent is a better choice than Earley.
In other words, recursive-descent is a smart modification of the Earley parsing schema for the purpose of serial parsing.

This view also highlights the downside of recursive-descent in comparison to Earley: the latter can easily reuse parse items and thus is a much more natural candidate whenever the parser is allowed to memorize and reuse parse items.
This makes Earley a much better choice for chart parsing and industrial applications.

\subsection{Adding Chart Parsing Techniques}

agenda

chart

\section{Left Recursion is Unproblematic}

When we looked at the recursive descent parser, we saw that left recursion can force it to enter an infinite loop of top-down predictions.
The shift-reduce and LC parsers do not run into this issue since they use bottom-up information.
The same is true of the Earley parser, which uses bottom-up information to restrict top-down predictions.
It is interesting to see, though, how exactly the Earley parser avoids infinite loops.
%
\begin{examplebox}[Earley Parse of Nested Possessive DPs]
    The sentence \emph{John's father's car's exhaust pipe disappeared} is to be analyzed with the following grammar:
    %
    \begin{center}
        \begin{tabular}{rcl@{\hspace{2em}}rcl}
            S    & \rewrite & DP VP
            & 
            Poss & \rewrite & 's \\
            DP   & \rewrite & DP D$'$ | PN
            & 
            N    & \rewrite & father | car | exhaust pipe
            \\
            D$'$ & \rewrite & Poss NP
            & 
            PN   & \rewrite & John
            \\
            NP   & \rewrite & N
            &
            V    & \rewrite & disappeared
            \\
            VP   & \rewrite & V
        \end{tabular}
    \end{center}
    
    Since the chart for this sentence is rather large, we look at individual cells instead.
    Cell $(0,0)$ starts out with the axiom S$'$ \rewrite\ \psep S, which this triggers a prediction of S \rewrite \psep DP VP\@.
    This item, in turn, yields two predictions: DP \rewrite \psep DP D$'$ and DP \rewrite \psep PN\@.
    The latter also adds PN \rewrite \psep John.
    The construction process of the cell is shown below.
    %
    \begin{center}
        \begin{tikzpicture}[cell/.style = { minimum width = 6em, minimum height = 8em, draw=gray!75, thick }]
            \node[cell] (0) [align=left] {%
                S$'$ \rewrite\ \psep S};

            \foreach \Source/\Target/\Label in {%
                0/1/{S$'$ \rewrite\ \psep S\\%
                     S \rewrite\ \psep DP VP},
                1/2/{S$'$ \rewrite\ \psep S\\%
                     S \rewrite\ \psep DP VP\\%
                     DP \rewrite\ \psep DP D'\\%
                     DP \rewrite\ \psep PN},
                2/3/{S$'$ \rewrite\ \psep S\\%
                     S \rewrite\ \psep DP VP\\%
                     DP \rewrite\ \psep DP D'\\%
                     DP \rewrite\ \psep PN\\%
                     PN \rewrite\ \psep John}%
                }
            {
                \node[cell] (\Target) [align=left, right=of \Source] {\Label};
                \draw[->] (\Source) to (\Target);
            }

            \node[fill=gray!75] at (0.north) {\textbf{Cell (0,0)}};
        \end{tikzpicture}
    \end{center}
    %
    At this point the scan rule reads in \emph{John} and thus adds PN \rewrite\ John \psep to cell $(0,1)$.
    This results in a number of complete step adding new items to the very same cell.
    %
    \begin{center}
        \begin{tikzpicture}[cell/.style = { minimum width = 6em, minimum height = 8em, draw=gray!75, thick }]
            \node[cell] (0) [align=left] {%
                PN \rewrite\ John \psep};

            \foreach \Source/\Target/\Label in {%
                0/1/{PN \rewrite\ John \psep\\%
                     DP \rewrite\ PN \psep},
                1/2/{PN \rewrite\ John \psep\\%
                     DP \rewrite\ PN \psep\\%
                     DP \rewrite\ DP \psep D$'$\\%
                     S  \rewrite\ DP \psep VP}%
                }
            {
                \node[cell] (\Target) [align=left, right=of \Source] {\Label};
                \draw[->] (\Source) to (\Target);
            }

            \node[fill=gray!75] at (0.north) {\textbf{Cell (0,1)}};
        \end{tikzpicture}
    \end{center}
    %
    The items in cell $(0,1)$ now trigger prediction steps that add items to cell $(1,1)$ for VP and D$'$.
    This subsequently yields predictions for V\@ and Poss, too.
    %
    \begin{center}
        \begin{tikzpicture}[cell/.style = { minimum width = 6em, minimum height = 8em, draw=gray!75, thick }]
            \node[cell] (0) [align=left] {%
                D$'$ \rewrite\ \psep Poss NP\\%
                VP \rewrite\ \psep V};

            \foreach \Source/\Target/\Label in {%
                0/1/{D$'$ \rewrite\ \psep Poss NP\\%
                     VP \rewrite\ \psep V\\%
                     Poss \rewrite \psep 's\\%
                     V \rewrite \psep disappeared}%
                }
            {
                \node[cell] (\Target) [align=left, right=of \Source] {\Label};
                \draw[->] (\Source) to (\Target);
            }

            \node[fill=gray!75] at (0.north) {\textbf{Cell (1,1)}};
        \end{tikzpicture}
    \end{center}
    %
    At this point scan can once again take place, reading in \emph{'s}.
    As a result, the completed rule Poss \rewrite 's\psep is added to cell $(1,2)$.
    Using this item, we can also add a partially completed D$'$ item.
    %
    \begin{center}
        \begin{tikzpicture}[cell/.style = { minimum width = 6em, minimum height = 8em, draw=gray!75, thick }]
            \node[cell] (0) [align=left] {%
                PN \rewrite\ 's \psep};

            \foreach \Source/\Target/\Label in {%
                0/1/{PN \rewrite 's \psep\\%
                     D$'$ \rewrite\ Poss \psep NP}%
                }
            {
                \node[cell] (\Target) [align=left, right=of \Source] {\Label};
                \draw[->] (\Source) to (\Target);
            }

            \node[fill=gray!75] at (0.north) {\textbf{Cell (1,2)}};
        \end{tikzpicture}
    \end{center}
    %
    The NP-prediction is added to cell $(2,2)$, and so are the N-predictions triggered by the item.
    %
    \begin{center}
        \begin{tikzpicture}[cell/.style = { minimum width = 6em, minimum height = 8em, draw=gray!75, thick }]
            \node[cell] (0) [align=left] {%
                NP \rewrite\ \psep N};

            \foreach \Source/\Target/\Label in {%
                0/1/{NP \rewrite\ \psep N\\%
                     N$'$ \rewrite\ \psep father\\%
                     N$'$ \rewrite\ \psep car\\%
                     N$'$ \rewrite\ \psep exhaust pipe}%
                }
            {
                \node[cell] (\Target) [align=left, right=of \Source] {\Label};
                \draw[->] (\Source) to (\Target);
            }

            \node[fill=gray!75] at (0.north) {\textbf{Cell (2,2)}};
        \end{tikzpicture}
    \end{center}
    %
    Scan now adds N \rewrite father\psep to cell $(2,3)$, which is also used to complete the NP item.
    As a result, we can add a completed D$'$ item to cell $(1,3)$.
    The completed D$'$ allows to put completed DPs into cell $(0,3)$, from which we infer a partially completed S item and add it to the same cell.
    %
    \begin{center}
        \begin{tikzpicture}[cell/.style = { minimum width = 6em, minimum height = 8em, draw=gray!75, thick }]
            \node[cell] (0) [align=left] {%
                DP \rewrite\ DP D$'$\psep};

            \foreach \Source/\Target/\Label in {%
                0/1/{DP \rewrite\ DP D$'$\psep\\%
                     DP \rewrite\ DP \psep D$'$\\%
                     S \rewrite DP \psep VP$'$}%
                }
            {
                \node[cell] (\Target) [align=left, right=of \Source] {\Label};
                \draw[->] (\Source) to (\Target);
            }

            \node[cell] (13) [align=left, left=of 0] {%
                D$'$ \rewrite Poss NP\psep};
            \node[cell] (23) [align=left, left=of 13] {%
                N \rewrite father\psep\\
                NP \rewrite N\psep};

            \foreach \Node/\Label in {0/{0,3}, 13/{1,3}, 23/{2,3}}
                \node[fill=gray!75] at (\Node.north) {\textbf{Cell (\Label)}};
        \end{tikzpicture}
    \end{center}

    Two crucial steps have taken place in the parse so far.
    First, the parser did not end up in a loop of left predictions at the very beginning.
    When the parser added DP \rewrite\ \psep DP D$'$ to cell $(0,0)$, it did not try to enter another instance of the item even though the corresponding predict rule is triggered by the addition of the item.
    The interplay of agenda and chart is to thank for that:
    %
    \begin{enumerate}
        \item When S \rewrite\ \psep DP VP is at the top of the agenda, it triggers the prediction of DP \rewrite\ \psep DP D$'$ and DP \rewrite\ \psep PN\@.
        \item Both items are added to the chart, and are also put in the agenda to indicate that no inference rules have been applied to them yet.
        \item In the next step, the parser computes the predictions of DP \rewrite \psep DP D$'$ and checks if some of them are not in the chart yet.
            This is not the case, and thus the chart stays the same.
        \item DP \rewrite\ \psep DP D$'$ is removed from the agenda and will not be operated on again.
    \end{enumerate}
    %
    The way items are moved in and out of the agenda and stored in the chart thus prevents an infinite loop of predictions.

    The other interesting aspect is the addition of DP \rewrite\ DP \psep D$'$ to cell $(0,3)$.
    The item is obtained from DP \rewrite DP D$'$\psep\ in cell $(0,3)$ and DP \rewrite\ \psep DP D' in cell $(0,0)$.
    This may seem surprising since the latter was already used in the assembly of \emph{John's father} into a DP\@.
    But strictly speaking it only represents the prediction of a DP that starts at position 0.
    Since the nested possessives construction has multiple DPs with this start position, the Earley parser is allowed to recycle the prediction accordingly.

    Proceeding in the very same fashion of recycling the DP prediction, the Earley parser can infer the structure for \emph{John's father's car's exhaust pipe disappeared} without major problems.
\end{examplebox}
%
\begin{exercise}
    Draw the full chart for the Earley parse of \emph{John's father's car's exhaust pipe disappeared}.
\end{exercise}

\section{The GHR Algorithm}

Several variants of Earley parsing have been proposed in the literature.
One of the fastest yet also intuitive ones is GHR parsing, originally proposed by Graham, Harrison and Ruzzo in \citeyear{Graham.EtAl80}.

GHR parsing relies on analyzing the grammar in advance and identifying those non-terminals from which one can generate the empty string.
In linguistic parlance, we have to identify those labels that may be the root of a subtree that consists only of unpronounced material.
There is little point in exploring such subtrees since the input can neither confirm nor disconfirm their existence.
Consequently, a $\psep$ to the left of such a node is allowed to move across it.
This strategy requires nothing more than some minor modifications to the Earley parsing schema.

\begin{prooftree}
    \AxiomC{$[i, A \rewrite \alpha \psep a \beta \gamma,j]$}
    \LeftLabel{\textbf{Scan}\qquad}
    \RightLabel{$a = w_{i}, \beta \rewrite^* \emptystring$}
    \UnaryInfC{$[i, A \rewrite \alpha a \beta \psep \gamma, j+1]$}
\end{prooftree}
%
\begin{prooftree}
    \AxiomC{$[i, A \rewrite \alpha \psep B \beta,j]$}
    \LeftLabel{\textbf{Predict}\qquad}
    \RightLabel{$B \rewrite^* C \gamma, \alpha' \rewrite^* \emptystring$}
    \UnaryInfC{$[j, C \rewrite \alpha' \psep \beta', j]$}
\end{prooftree}
%
\begin{prooftree}
    \AxiomC{$[i, A \rewrite \alpha \psep B \beta \gamma,j]$}
    \AxiomC{$[j, B \rewrite \delta \psep,k]$}
    \LeftLabel{\textbf{Complete1}\qquad}
    \RightLabel{$\beta \rewrite^* \emptystring$}
    \BinaryInfC{$[i, A \rewrite \alpha B \beta \psep \gamma,k]$}
\end{prooftree}
%
\begin{prooftree}
    \AxiomC{$[i, A \rewrite \alpha \psep B \beta \gamma,j]$}
    \AxiomC{$[j, C \rewrite \delta \psep,k]$}
    \LeftLabel{\textbf{Complete2}\qquad}
    \RightLabel{$B \rewrite^* C, \beta \rewrite^* \emptystring$}
    \BinaryInfC{$[i, A \rewrite \alpha B \beta \psep \gamma,k]$}
\end{prooftree}

Side conditions of the form $\alpha \rewrite^* \beta$ express that either $\alpha = \beta$ or $\beta$ can be obtained from $\alpha$ in one or more rewrite steps.
For any given CFG, whether $B \rewrite^* C \gamma$ and $B \rewrite^* \emptystring$ can be determined in advance.
This can then be precompiled into the parser, e.g.\ in form of a boolean matrix.
This matrix contains a row for each non-terminal symbol as well as a column for each non-terminal symbol and the empty string.
A cell $(B,C)$ has value $1$ iff $B \rewrite^* C \gamma$, and similarly $(B,\emptystring)$ is 1 iff $B \rewrite \emptystring$ (the latter is just a special case of the former).
This strategy can be extended to sequences of non-terminals so that even $\alpha' \rewrite^* \emptystring$ in the predict rule can be verified in a single step.

\begin{exercise}
    Every inference step in the Earley parse schema is still a valid inference step in the GHR parse schema.
    Explain why!
\end{exercise}

GHR parsing is an obvious variant of Earley parsing.
That does not make it less of a parser, its speed-up over standard Earley parsing is a notable achievement.
It also shows that parsing schemata highlight commonalities between distinct parsing algorithms.
The relations between parsers that can be established this way extend far beyond simple cases like Earley and GHR\@.
In the next chapter, we will establish principled connections between Earley, CKY, and LC parsing.

\bibliographystyle{./bib/linquiry3}
\bibliography{./bib/universal,./bib/graf}
